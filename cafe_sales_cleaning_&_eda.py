# -*- coding: utf-8 -*-
"""Cafe Sales cleaning & EDA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N10UXQx7yofsyUjyxxZN9asFDN5-bcRO
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training")

print("Path to dataset files:", path)

import pandas as pd
import os

# List files in the downloaded directory to find the CSV file
file_list = os.listdir(path)
print("Files in the downloaded directory:", file_list)

# Assuming the CSV file is the first file in the directory, or you know its name
# You might need to adjust the filename based on the output of listdir
csv_file_path = os.path.join(path, file_list[0])

df = pd.read_csv(csv_file_path)
df.head()

"""Import required Dependencies"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
import mplcursors
import plotly.express as px

# Get to understand data
df.info()

"""We have 1000 data entries (rows) and 8 columns. As we can see the data is messy. All data types are labeled as object.

## Data cleaning step by step
"""

# Replace gaps in columns and Capitalize first letter
df.columns = df.columns.str.replace(' ', '_').str.capitalize()

# check the columns
df.columns

# change the data types of numeric columns and date
df['Quantity'] = pd.to_numeric(df['Quantity'], errors = 'coerce')

df['Price_per_unit'] = pd.to_numeric(df['Price_per_unit'], errors = 'coerce')

df['Total_spent'] = pd.to_numeric(df['Total_spent'], errors = 'coerce')

df['Transaction_date'] = pd.to_datetime(df['Transaction_date'], errors = 'coerce')

# Replace Unknown and errors with null values
df.replace(['UNKNOWN', 'ERROR'], np.nan, inplace = True)

# check if change have been applied
df['Location'].value_counts(dropna=False)

# check Items we are dealing with
df['Item'].unique()

"""##Dealing with missing data"""

# number of nulls in every columns
df.isna().sum()

#Visualize the missing data
msno.matrix(df)

plt.show()

"""The graph shows how our data is missing — every white space represent missing data.

It seems payment method and Location have a lot of missing values. Let's deal with them.


---


"""

# Fill missing values in categorical columns with mode
df['Location'] = df['Location'].fillna(df['Location'].mode()[0])

df['Payment_method'] = df['Payment_method'].fillna(df['Payment_method'].mode()[0])
#df['Item'] = df['Item'].fillna(df['Item'].mode()[0])

# Select where price is null and quantity and Total spent are not null
fill_price = df['Price_per_unit'].isna()& df['Total_spent'].notna()& df['Quantity'].notna()

# fill missing values in price column by diving total spent with Quantity
df.loc[fill_price, 'Price_per_unit'] = df.loc[fill_price, 'Total_spent'] / df.loc[fill_price, 'Quantity']

# Create dict of unique items and their prices
price_item_reverse = {
    2.0: 'Coffee',
    1.0: 'Cookie',
    3.0: 'Juice',
    5.0: 'Salad',
    4.0: 'Sandwich',
    1.5: 'Tea'
}

# Fill missng data in Item with corresponding price from dictionery
df['Item'] = df['Item'].fillna(df['Item'].map(price_item_reverse))

# create threshold of 10% to drop
threshold = 0.1

# drop rows in columns where nul values are below the threshold
columns_to_drop = df.columns[df.isnull().mean() < threshold].tolist()
df.dropna(subset=columns_to_drop, inplace=True)

df.isna().sum()

"""We have dealt with missing data and other anomalies.  
Now we can go the next level of Exploratory Analysis.

---

#Explatory Data Analysis
"""

# Get statistical understnding of data.
df.describe()

# check data shape.
df.shape

"""Sales made during the Period."""

# Revenue
df['Total_spent'].sum()

# Sales by Items
Item_sales = df.groupby('Item')['Total_spent'].sum().sort_values(ascending=False)

# Top five by sales
Item_sales.head(5)

# Bottom Item by sales
Item_sales.tail(4)

"""Datetime Analysis"""

# Extract periods
df['Year']  = df['Transaction_date'].dt.year
df['Month'] = df['Transaction_date'].dt.strftime('%B')
df['Day']   = df['Transaction_date'].dt.day
df['Hour']  = df['Transaction_date'].dt.hour

# sales by month
monthly_sales = df.groupby('Month')['Total_spent'].sum()

#Calculate the mean of monthly sales
mean_monthly_sales = monthly_sales.mean()

# sort the months numerically
monthly_sales = monthly_sales.sort_index(key=lambda x: pd.to_datetime(x, format='%B'))
plt.figure(figsize=(10, 6))
# Now plot
sns.lineplot(x=monthly_sales.index, y=monthly_sales.values, marker='o')
plt.title('Monthly Sales Trend')
plt.xlabel('Month')
plt.xticks(rotation=45)
plt.ylabel('Total Sales')
plt.grid(True)
plt.axhline(y=mean_monthly_sales, color='r', linestyle='--', label=f'Mean: {mean_monthly_sales:.2f}')
plt.legend()
mplcursors.cursor(hover=True)
plt.show()

"""Data shows that month of February we experienced very  the low sales compared to mean — dotted line coloured red.

Again graph shows month of January, March, June, August, October and December are only months we sold above average.

June is the month we made a lot of sales by making over $6700

---

##Distribution
"""

sns.histplot(data=df, x='Total_spent', kde = True)
plt.title('distribution of Total spent')
plt.show()

"""The bars in graph above shows how many times different spending amount occurred.  
The smooth blue curve line(KDE) shows smooth version of distribution. Y-axis shows the frequency.

Most bars are bunched to the left from 1 - 10 and few bars beyond 15 and 20. This distribution is *right skewed*.

This means most customers spend small amounts of money and few spend significantly more.

---

##Box Plot
"""

sns.catplot(data=df, kind='box', x='Item', y='Total_spent', palette='rainbow')
plt.xticks(rotation=45)
plt.title('Box plot of Total_spent by Item')
plt.grid(True)
plt.show()

"""Salad has high median of $15, wider variation in spent and long whiskers. It's top spender, customers spend differently.

Smoothie, Juice and Sandwich have median of around $12-15 and almost the same wide range. They attract diverse buyers. Outliers might indicate a toppings.

Cookie and Tea have low median as $ 3 or 4 and spread.

---


"""

# Numerical variable distributions with box plots
numerical_cols = ['Quantity', 'Price_per_unit', 'Total_spent']

for col in numerical_cols:
    plt.figure(figsize=(8, 6))
    sns.boxplot(y=df[col])
    plt.title(f'Box plot of {col}')
    plt.xlabel(col)
    plt.show()

"""###Comapare weekday and weekend sales"""

df['weekday'] = df['Transaction_date'].dt.dayofweek
df['Day_type'] = df['weekday'].apply(lambda x: 'weekend' if x >= 5 else 'weekday')
sales_by_day_type = df.groupby('Day_type')['Total_spent'].sum().reset_index() # Convert Series to DataFrame

plt.figure(figsize=(8, 5))
sns.barplot(x='Day_type', y='Total_spent', data=sales_by_day_type)
plt.title('Total Sales by Day Type (Weekday vs Weekend)')
plt.xlabel('Day Type')
plt.ylabel('Total Sales')
plt.grid(True)
mplcursors.cursor(hover=True)
plt.show()

"""We would expect Cafes to make more sales in weekends than during normal days of the week but that is not the case.

---

###Comparing Item sales in weekend and weekdays
"""

# Group by Day_type and Item and calculate the sum of Quantity
item_sales_by_day_type = df.groupby(['Day_type', 'Item'])['Quantity'].sum().reset_index()

# Create a bar plot
plt.figure(figsize=(12, 7))
sns.barplot(data=item_sales_by_day_type, x='Item', y='Quantity', hue='Day_type')
plt.title('Quantity of Items Sold during Weekend and Weekday')
plt.xlabel('Item')
plt.ylabel('Total Quantity Sold')
plt.xticks(rotation=45, ha='right')
plt.legend(title='Day Type')
plt.tight_layout()
mplcursors.cursor(hover=True)
plt.show()

col_list = df.select_dtypes(include='object').columns.drop(['Transaction_id','Month', 'Day_type']).to_list()
for col in col_list:
    saes_by_cat = df.groupby(col)['Total_spent'].sum().sort_values(ascending=False)
    plt.figure(figsize=(8, 4))
    sns.barplot(x=saes_by_cat.index, y=saes_by_cat.values)
    plt.title(f'Distribution of Total Spent by {col}')
    plt.xticks(rotation =45)
    mplcursors.cursor(hover=True)
    plt.show()

# correlation

numerical_df = df[['Total_spent', 'Quantity', 'Price_per_unit']] # Select only numerical columns
sns.heatmap(numerical_df.corr(), annot=True, cmap='coolwarm', fmt = '.2f')
plt.title('Correlation Heatmap')
plt.show()

"""According to above heatmap, there is no correlation between price and quantity.

Quantity spent have a correlation of 0.7

---


"""

sns.scatterplot(data=df, y='Quantity', x='Price_per_unit')
plt.title('Quantity vs Total_spent')
plt.grid(True)
plt.show()

"""Price and quantity are evenly distributed. There is no correlation.

---


"""

sns.pairplot(df[['Total_spent', 'Quantity', 'Price_per_unit']])
plt.show()